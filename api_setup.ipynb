{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edwardhongwang/2025_Spring_ES26_ES294-/blob/main/api_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13i7KQ9t-CV8"
      },
      "source": [
        "\n",
        "# Welcome to the Harvard ES 26 and ES 294 Recitation 3\n",
        "\n",
        "\n",
        "\n",
        "# **API Setup**\n",
        "\n",
        "\n",
        "\n",
        "Expected completion time: 20 min\n",
        "\n",
        "\n",
        "## March 10, 2025  <br> Edward Hong Wang\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TL;DR** In this notebook you will find instructions to setup your OpenAI and HuggingFace API keys for the tutorial.\n",
        "\n",
        "<!--\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Agfj2lsK155vzmvG6vB4dScH7RqUWV9B\" alt=\"drawing\" width=\"400\"/> -->\n",
        "\n",
        "<!-- <img src=\"https://drive.google.com/uc?export=view&id=11o2zAv2_Cu8BL-FVdoRY8z5IEruO3ElZ\" alt=\"drawing\" width=\"400\"/> -->\n",
        "\n",
        "<!-- https://drive.google.com/file/d/11o2zAv2_Cu8BL-FVdoRY8z5IEruO3ElZ/view?usp=sharing -->\n"
      ],
      "metadata": {
        "id": "rMVhWY7bxfNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "üîë First, we need an OpenAI API Key since we will use ChatGPT for many demos. Don't worry üòâ , you can easily switch to other LLM provider if you prefer. But you'll need to work out yourself setting up their API keys.\n",
        "\n",
        "\n",
        "ü§ó You will also need a HuggingFace token for interfacing directly with the LLM weights and code (as opposed to using their call APIs).\n",
        "\n",
        "üïµÔ∏è‚Äç‚ôÇÔ∏è In addition to the HuggingFace token, you need to request access to the LLamaModels that we'll be using in the demo.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1agwSn9ZKa7y-QgQ4YrmpKLwv2c7IZY_w\" alt=\"drawing\" width=\"400\"/>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BPO_LtqGh2jr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open AI API Key\n",
        "\n",
        "\n",
        "**Step 1:** Obtain the OpenAI API key from the OpenAI platform website.\n",
        "\n",
        "1. Visit the [OpenAI Platform Website](https://auth.openai.com/). Create an account.\n",
        "2. Log in, go to `Dashboard` on the Top Menu, then `API keys` on the left sidebar. Finally, select `+Create new secret Key` from the top right corner.\n",
        "3. Choose a name for your key (e.g., `GoogleColab`). Below is the screenshot of the screen you should be at.\n",
        "\n",
        "4. Clock on `Create secret key`, and it will take you to your API key. You must copy this key and store it for the next step.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=14Mu4cgk1Js8Az79gQrkmsaaLSC5LXgEJ\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1oqGFLgYKG_VWHuJRF0Wt3VXOV6qg78on\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "**Step 2:** Add to the Google Colab Notebook Secrets\n",
        "\n",
        "1. On a Colab notebook (e.g., this one), open the fourth menu of the left sidebar, which has a key icon üîë.\n",
        "\n",
        "2. Click on `+ Add new secret`. On the column named name, input `OPENAI_API_KEY`. Then on the column named Value, paste the value of the API key you previously copied.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CjR_VZh_aMuQbZeRLxjrxpDfCQEbu7iB\" alt=\"drawing\" width=\"400\"/>\n"
      ],
      "metadata": {
        "id": "lfJrR6UJmp8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test OpenAI API\n",
        "\n",
        "Let's now test with a simple LLM call."
      ],
      "metadata": {
        "id": "UEnnwVhTufFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first install the require packages\n",
        "%pip install -q openai"
      ],
      "metadata": {
        "id": "-02EzY0iqyhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "fGl3fPg7uqBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "client = openai.OpenAI()\n",
        "\n",
        "client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about Ai and Machine learning\"}],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga_EVfXuu4dq",
        "outputId": "f94790f9-6bf3-403a-ae9f-a7ee6a3e9be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-B9DJdXOT1axcBPkHNs21I2gXXcrYZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Why did the AI break up with its partner?\\n\\nBecause it felt it was in a \"supervised\" relationship and wanted more \"unsupervised\" freedom!', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1741535837, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_06737a9306', usage=CompletionUsage(completion_tokens=33, prompt_tokens=16, total_tokens=49, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face\n",
        "\n",
        "The previous LLM call happen entiredly on a remote server hosted by OpenAI. Let's see if we can download an entire LLM and use it to generate text.\n",
        "\n",
        "**Step 1**: Obtain the HuggingFace token.\n",
        "\n",
        "1. Go the [HuggingFace portal](https://huggingface.co/). Log in (create an account if needed).\n",
        "2. Click on your avatar on the right corner (small circle), which will open the settings right sidebar. Then go to `Access Tokens`.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1kb45vIZCK1EWVumMuYCMrDwsu7NMPUSz\" alt=\"drawing\" width=\"500\"/>\n",
        "\n",
        "3. Select `+Create new token` in the new menu. Then select any name (e.g., `ColabTest`). the permission level (write is ok), and finally, click on `Create token` again. Lastly, copy the new key (copy button), which will be added to Colab in the next step in the same way as the Open AI key.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Vfayo4auZ3Y6_UgNknMmylkBDstY4WKU\" alt=\"drawing\" width=\"500\"/>\n",
        "\n",
        "\n",
        "**Step 2:** Add to the Google Colab Notebook Secrets\n",
        "\n",
        "1. On a Colab notebook (e.g., this one), open the fourth menu of the left sidebar, which has a key on the icon üîë.\n",
        "\n",
        "2. Click on `+ Add new secret`. On the column named name, input `HF_TOKEN`. Then on the column named Value, paste the value of the API key you previously copied.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CjR_VZh_aMuQbZeRLxjrxpDfCQEbu7iB\" alt=\"drawing\" width=\"400\"/>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OwiqJQeqvvmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test HF Token Through Deepseek R1 1.5B model\n"
      ],
      "metadata": {
        "id": "fQGOMWFg2mQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q transformers[torch] # HF main module for LLMs"
      ],
      "metadata": {
        "id": "4ZF3tYI-2lmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "import os\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "\n",
        "model = \"tiiuae/falcon-rw-1b\"\n",
        "\n",
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you? \"},\n",
        "]\n",
        "pipe = pipeline(\"text-generation\", model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", max_length=300)\n",
        "pipe(messages)"
      ],
      "metadata": {
        "id": "OQLp35W22i6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5fe70f-0622-44a4-9396-d37b1f83ee17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': [{'role': 'user', 'content': 'Who are you? '},\n",
              "   {'role': 'assistant',\n",
              "    'content': \"Greetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\\n</think>\\n\\nGreetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\"}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzeHYa5GCxN7"
      },
      "outputs": [],
      "source": [
        "# MIT License\n",
        "#\n",
        "# @title Copyright (c) 2025 Mauricio Tec { display-mode: \"form\" }\n",
        "\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}